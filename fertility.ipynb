{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf6963f-4897-49b0-8916-d449cceee29f",
   "metadata": {},
   "source": [
    "# Fertility Dataset w/ Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a954cd12-af1d-490e-a190-9ba8ac2eb6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 244, 'name': 'Fertility', 'repository_url': 'https://archive.ics.uci.edu/dataset/244/fertility', 'data_url': 'https://archive.ics.uci.edu/static/public/244/data.csv', 'abstract': '100 volunteers provide a semen sample analyzed according to the WHO 2010 criteria. Sperm concentration are related to socio-demographic data, environmental factors, health status, and life habits', 'area': 'Health and Medicine', 'tasks': ['Classification', 'Regression'], 'characteristics': ['Multivariate'], 'num_instances': 100, 'num_features': 9, 'feature_types': ['Real'], 'demographics': ['Age'], 'target_col': ['diagnosis'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2012, 'last_updated': 'Fri Mar 15 2024', 'dataset_doi': '10.24432/C5Z01Z', 'creators': ['David Gil', 'Jose Girela'], 'intro_paper': {'ID': 429, 'type': 'NATIVE', 'title': 'Predicting seminal quality with artificial intelligence methods', 'authors': 'David Gil, J. L. Girela, Joaquin De Juan, M. Jose Gomez-Torres, Magnus Johnsson', 'venue': 'Expert systems with applications', 'year': 2012, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/Predicting-seminal-quality-with-artificial-methods-Gil-Girela/92759c5ee08b9e6e7b17d1ccd48a7f8c02aba893', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': None, 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Season in which the analysis was performed. \\t1) winter, 2) spring, 3) Summer, 4) fall. \\t(-1, -0.33, 0.33, 1) \\r\\n\\r\\nAge at the time of analysis. \\t18-36 \\t(0, 1) \\r\\n\\r\\nChildish diseases (ie , chicken pox, measles, mumps, polio)\\t1) yes, 2) no. \\t(0, 1) \\r\\n\\r\\nAccident or serious trauma \\t1) yes, 2) no. \\t(0, 1) \\r\\n\\r\\nSurgical intervention \\t1) yes, 2) no. \\t(0, 1) \\r\\n\\r\\nHigh fevers in the last year \\t1) less than three months ago, 2) more than three months ago, 3) no. \\t(-1, 0, 1) \\r\\n\\r\\nFrequency of alcohol consumption \\t1) several times a day, 2) every day, 3) several times a week, 4) once a week, 5) hardly ever or never \\t(0, 1) \\r\\n\\r\\nSmoking habit \\t1) never, 2) occasional 3) daily. \\t(-1, 0, 1) \\r\\n\\r\\nNumber of hours spent sitting per day \\tene-16\\t(0, 1) \\r\\n\\r\\nOutput: Diagnosis\\tnormal (N), altered (O)\\t\\r\\n', 'citation': None}}\n",
      "                    name     role         type demographic description units  \\\n",
      "0                 season  Feature   Continuous        None        None  None   \n",
      "1                    age  Feature      Integer         Age        None  None   \n",
      "2         child_diseases  Feature       Binary        None        None  None   \n",
      "3               accident  Feature       Binary        None        None  None   \n",
      "4  surgical_intervention  Feature       Binary        None        None  None   \n",
      "5            high_fevers  Feature  Categorical        None        None  None   \n",
      "6                alcohol  Feature  Categorical        None        None  None   \n",
      "7                smoking  Feature  Categorical        None        None  None   \n",
      "8            hrs_sitting  Feature      Integer        None        None  None   \n",
      "9              diagnosis   Target       Binary        None        None  None   \n",
      "\n",
      "  missing_values  \n",
      "0             no  \n",
      "1             no  \n",
      "2             no  \n",
      "3             no  \n",
      "4             no  \n",
      "5             no  \n",
      "6             no  \n",
      "7             no  \n",
      "8             no  \n",
      "9             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# fetch dataset \n",
    "fertility = fetch_ucirepo(id=244) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = fertility.data.features \n",
    "y = fertility.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(fertility.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(fertility.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff69972a-55c5-4fc2-a256-f1f08f0bf8c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   season   age  child_diseases  accident  surgical_intervention  high_fevers  \\\n",
      "0   -0.33  0.69               0         1                      1            0   \n",
      "1   -0.33  0.94               1         0                      1            0   \n",
      "2   -0.33  0.50               1         0                      0            0   \n",
      "3   -0.33  0.75               0         1                      1            0   \n",
      "4   -0.33  0.67               1         1                      0            0   \n",
      "\n",
      "   alcohol  smoking  hrs_sitting  \n",
      "0      0.8        0         0.88  \n",
      "1      0.8        1         0.31  \n",
      "2      1.0       -1         0.50  \n",
      "3      1.0       -1         0.38  \n",
      "4      0.8       -1         0.50  \n",
      "season                   0\n",
      "age                      0\n",
      "child_diseases           0\n",
      "accident                 0\n",
      "surgical_intervention    0\n",
      "high_fevers              0\n",
      "alcohol                  0\n",
      "smoking                  0\n",
      "hrs_sitting              0\n",
      "dtype: int64\n",
      "season                   float64\n",
      "age                      float64\n",
      "child_diseases             int64\n",
      "accident                   int64\n",
      "surgical_intervention      int64\n",
      "high_fevers                int64\n",
      "alcohol                  float64\n",
      "smoking                    int64\n",
      "hrs_sitting              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.head())\n",
    "print(X.isnull().sum())\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e3000dd-9136-4594-8662-a324d7666891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates in X and align y accordingly\n",
    "X = X.drop_duplicates()\n",
    "y = fertility.data.targets.iloc[X.index]  # Align y based on the dropped duplicates of X\n",
    "y = y.iloc[:, 0].map({'N': 1, 'O': -1}).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4adfe61-ccec-428b-a877-7a925d8324cd",
   "metadata": {},
   "source": [
    "#### Shuffle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f64bed0-93c6-4161-9ccf-15bff48e18fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_and_Y= np.hstack([X, y.reshape(-1,1)])\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(X_and_Y)\n",
    "X = X_and_Y[:, :-1]\n",
    "y = X_and_Y[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3da5644b-f93a-4d17-9a22-968117960332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "total_samples = X.shape[0]\n",
    "print(total_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07559d36-cf2b-45d0-8431-a9fe3471ac28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracies for Each Hyperparameter Combination:\n",
      "--------------------------------------------------\n",
      "Parameters: {'max_depth': 5, 'min_samples_split': 2}, Validation Accuracy: 0.8380\n",
      "Parameters: {'max_depth': 5, 'min_samples_split': 10}, Validation Accuracy: 0.6961\n",
      "Parameters: {'max_depth': 5, 'min_samples_split': 20}, Validation Accuracy: 0.6859\n",
      "Parameters: {'max_depth': 10, 'min_samples_split': 2}, Validation Accuracy: 0.8482\n",
      "Parameters: {'max_depth': 10, 'min_samples_split': 10}, Validation Accuracy: 0.6961\n",
      "Parameters: {'max_depth': 10, 'min_samples_split': 20}, Validation Accuracy: 0.6859\n",
      "Parameters: {'max_depth': None, 'min_samples_split': 2}, Validation Accuracy: 0.8482\n",
      "Parameters: {'max_depth': None, 'min_samples_split': 10}, Validation Accuracy: 0.6961\n",
      "Parameters: {'max_depth': None, 'min_samples_split': 20}, Validation Accuracy: 0.6859\n",
      "\n",
      "Best Hyperparameters:\n",
      "  {'max_depth': 10, 'min_samples_split': 2}\n",
      "Validation Accuracy with Best Hyperparameters: 0.8482\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters - need to use cross validation and compute validation accuracy\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 10, 20]\n",
    "}\n",
    "\n",
    "# Hyperparamter tuning in order to get the best hyperparameters - perform a 3-fold cross-validation\n",
    "clf = DecisionTreeClassifier(random_state=42, class_weight = 'balanced')\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=2, n_jobs=-1, scoring='accuracy', return_train_score=True)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Extract and display the validation accuracy for each combination\n",
    "print(\"Validation Accuracies for Each Hyperparameter Combination:\")\n",
    "print(\"-\" * 50)\n",
    "cv_results = grid_search.cv_results_\n",
    "for mean_val_acc, params in zip(cv_results['mean_test_score'], cv_results['params']):\n",
    "    print(f\"Parameters: {params}, Validation Accuracy: {mean_val_acc:.4f}\")\n",
    "\n",
    "# Best hyperparameters based on validation accuracy\n",
    "best_params = grid_search.best_params_\n",
    "best_validation_accuracy = grid_search.best_score_\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"  {best_params}\")\n",
    "print(f\"Validation Accuracy with Best Hyperparameters: {best_validation_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a00df68f-2899-4038-bbbc-3db188376d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 80/20 Split:\n",
      "Train Accuracy: 1.0000\n",
      "Test Accuracy: 0.7667\n",
      "--------------------------------------------------\n",
      "Results for 50/50 Split:\n",
      "Train Accuracy: 1.0000\n",
      "Test Accuracy: 0.8667\n",
      "--------------------------------------------------\n",
      "Results for 20/80 Split:\n",
      "Train Accuracy: 1.0000\n",
      "Test Accuracy: 0.7583\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Partition splits with 80/20, 50/50, 20/80\n",
    "splits = [(.8, .2), (.5, .5), (.2, .8)]\n",
    "results = {}\n",
    "split_results = []  # Store split-wise metrics\n",
    "\n",
    "# Outer loop for each partition\n",
    "for split in splits:\n",
    "    train_size, test_size = split\n",
    "    trial_accuracies = {'train': [], 'test': []}\n",
    "    trial_precisions = []\n",
    "    trial_recalls = []\n",
    "    trial_f1_scores = []\n",
    "\n",
    "    # Inner loop to run 3 trials per split\n",
    "    for trial in range(3): \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None, stratify=y)\n",
    "\n",
    "        # Retrain the model with the best hyperparameters\n",
    "        best_clf = DecisionTreeClassifier(\n",
    "            max_depth=best_params['max_depth'], \n",
    "            min_samples_split=best_params['min_samples_split'], \n",
    "            random_state=42\n",
    "        )\n",
    "        best_clf.fit(X_train, y_train)\n",
    "\n",
    "        # Compute train accuracy\n",
    "        y_train_pred = best_clf.predict(X_train)\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "        trial_accuracies['train'].append(train_accuracy)\n",
    "\n",
    "        # Compute test accuracy\n",
    "        y_test_pred = best_clf.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        trial_accuracies['test'].append(test_accuracy)\n",
    "\n",
    "        # Calculate precision, recall, and F1-score\n",
    "        trial_precisions.append(precision_score(y_test, y_test_pred, average=\"weighted\", zero_division=0))\n",
    "        trial_recalls.append(recall_score(y_test, y_test_pred, average=\"weighted\"))\n",
    "        trial_f1_scores.append(f1_score(y_test, y_test_pred, average=\"weighted\"))\n",
    "\n",
    "    # Average metrics over the 3 trials for the current split\n",
    "    avg_train_accuracy = np.mean(trial_accuracies['train'])\n",
    "    avg_test_accuracy = np.mean(trial_accuracies['test'])\n",
    "    avg_precision = np.mean(trial_precisions)\n",
    "    avg_recall = np.mean(trial_recalls)\n",
    "    avg_f1_score = np.mean(trial_f1_scores)\n",
    "\n",
    "    # Save split-level metrics\n",
    "    split_results.append({\n",
    "        'Split': f\"{int(train_size * 100)}/{int(test_size * 100)}\",\n",
    "        'Test Accuracy': avg_test_accuracy,\n",
    "        'Precision': avg_precision,\n",
    "        'Recall': avg_recall,\n",
    "        'F1-Score': avg_f1_score\n",
    "    })\n",
    "\n",
    "    # Print split-specific results\n",
    "    print(f\"Results for {int(train_size * 100)}/{int(test_size * 100)} Split:\")\n",
    "    print(f\"Train Accuracy: {avg_train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {avg_test_accuracy:.4f}\")\n",
    "    # print(f\"Precision: {avg_precision:.4f}\")\n",
    "    # print(f\"Recall: {avg_recall:.4f}\")\n",
    "    # print(f\"F1-Score: {avg_f1_score:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# # Save the metrics to use later for the summary table\n",
    "# print(\"Overall Metrics for Decision Tree Classifier (Autism Dataset):\")\n",
    "# print(f\"Overall Accuracy: {overall_accuracy_1:.4f}\")\n",
    "# print(f\"Overall Precision: {overall_precision_1:.4f}\")\n",
    "# print(f\"Overall Recall: {overall_recall_1:.4f}\")\n",
    "# print(f\"Overall F1-Score: {overall_f1_score_1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22709530-03a0-43c6-989c-3d8eb0f58b16",
   "metadata": {},
   "source": [
    "#### Results for Decision Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cadbe2a-12a3-4d15-8a84-da5aacc613fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Results on Fertility Dataset:\n",
      "Split     ACC            Precision      Recall         F1-Score       \n",
      "-----------------------------------------------------------------\n",
      "80/20     0.7667         0.8190         0.7667         0.7883         \n",
      "50/50     0.8667         0.8583         0.8667         0.8598         \n",
      "20/80     0.7583         0.8191         0.7583         0.7797         \n",
      "-----------------------------------------------------------------\n",
      "Overall   0.7972         0.8322         0.7972         0.8093         \n"
     ]
    }
   ],
   "source": [
    "# Calculate overall metrics for the Decision Tree classifier\n",
    "overall_accuracy_1 = np.mean([r['Test Accuracy'] for r in split_results])\n",
    "overall_precision_1 = np.mean([r['Precision'] for r in split_results])\n",
    "overall_recall_1 = np.mean([r['Recall'] for r in split_results])\n",
    "overall_f1_score_1 = np.mean([r['F1-Score'] for r in split_results])\n",
    "# Create a formatted table for the split results\n",
    "print(\"Decision Tree Classifier Results on Fertility Dataset:\")\n",
    "print(f\"{'Split':<10}{'ACC':<15}{'Precision':<15}{'Recall':<15}{'F1-Score':<15}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# Loop through the split results and display each row\n",
    "for result in split_results:\n",
    "    print(f\"{result['Split']:<10}{result['Test Accuracy']:<15.4f}{result['Precision']:<15.4f}{result['Recall']:<15.4f}{result['F1-Score']:<15.4f}\")\n",
    "\n",
    "# Print the overall metrics as the last row\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'Overall':<10}{overall_accuracy_1:<15.4f}{overall_precision_1:<15.4f}{overall_recall_1:<15.4f}{overall_f1_score_1:<15.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03948353-fbf3-4742-92e8-311263bc7c78",
   "metadata": {},
   "source": [
    "### Classifier #2: SVM (with RBF kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aefdac9c-d35d-4c38-a261-c286132b2763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracies for Each Hyperparameter Combination:\n",
      "==================================================\n",
      "Parameters: {'C': 1, 'gamma': 1e-06, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 1, 'gamma': 1e-05, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 10, 'gamma': 1e-06, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 100, 'gamma': 1e-06, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 1000, 'gamma': 1e-06, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}, Validation Accuracy: 0.8485\n",
      "Parameters: {'C': 10000, 'gamma': 1e-06, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 10000, 'gamma': 1e-05, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 10000, 'gamma': 0.0001, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 10000, 'gamma': 0.001, 'kernel': 'rbf'}, Validation Accuracy: 0.8889\n",
      "Parameters: {'C': 10000, 'gamma': 0.01, 'kernel': 'rbf'}, Validation Accuracy: 0.8384\n",
      "\n",
      "Best Hyperparameters:\n",
      "  {'C': 1, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "Validation Accuracy with Best Hyperparameters: 0.8889\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for SVM\n",
    "param_grid = {\n",
    "    'C': [1, 10, 100, 1000, 10000],\n",
    "    'gamma': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# Set up the SVM model\n",
    "svm = SVC()\n",
    "\n",
    "# Perform GridSearchCV on the entire dataset (no need for X_train, Y_train if you're not splitting beforehand)\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=3, scoring='accuracy', return_train_score=True)  # 3-fold cross-validation\n",
    "\n",
    "# Fit the model (this performs the search)\n",
    "grid_search.fit(X, y)  # Use the entire dataset here, not just the training set\n",
    "\n",
    "# Extract the results from the grid search\n",
    "cv_results = grid_search.cv_results_\n",
    "\n",
    "# Print the validation accuracies for each hyperparameter combination\n",
    "print(\"Validation Accuracies for Each Hyperparameter Combination:\")\n",
    "print(\"=\" * 50)\n",
    "for mean_val_acc, params in zip(cv_results['mean_test_score'], cv_results['params']):\n",
    "    print(f\"Parameters: {params}, Validation Accuracy: {mean_val_acc:.4f}\")\n",
    "\n",
    "# Best hyperparameters based on validation accuracy\n",
    "best_params = grid_search.best_params_\n",
    "best_validation_accuracy = grid_search.best_score_\n",
    "\n",
    "# Print the best hyperparameters and the corresponding validation accuracy\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"  {best_params}\")\n",
    "print(f\"Validation Accuracy with Best Hyperparameters: {best_validation_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "256af6b9-9ed9-4f84-8c00-10584d3b110b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for 80/20 Split:\n",
      "Train Accuracy: 0.8861\n",
      "Test Accuracy: 1.0000\n",
      "--------------------------------------------------\n",
      "\n",
      "Results for 50/50 Split:\n",
      "Train Accuracy: 0.8980\n",
      "Test Accuracy: 0.8800\n",
      "--------------------------------------------------\n",
      "\n",
      "Results for 20/80 Split:\n",
      "Train Accuracy: 0.8947\n",
      "Test Accuracy: 0.8906\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Best hyperparameters obtained from GridSearchCV\n",
    "best_C = 1\n",
    "best_gamma = 1e-06\n",
    "\n",
    "# Split ratios\n",
    "split_ratios = [(0.8, 0.2), (0.5, 0.5), (0.2, 0.8)]\n",
    "split_results_svm_2 = []\n",
    "\n",
    "# Iterate over splits\n",
    "for train_size, test_size in split_ratios:\n",
    "    trial_train_accuracies = []\n",
    "    trial_validation_accuracies = []\n",
    "    trial_test_accuracies = []\n",
    "    trial_precisions = []\n",
    "    trial_recalls = []\n",
    "    trial_f1_scores = []\n",
    "    \n",
    "    for _ in range(3):  # Perform 3 trials for each split\n",
    "        # Split the data into train and temp (validation + test)\n",
    "        X_train, X_temp, Y_train, Y_temp = train_test_split(X, y, train_size=train_size, stratify=y, random_state=None)\n",
    "        \n",
    "        # Now split the temp data into validation and test\n",
    "        X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=test_size, stratify=Y_temp, random_state=None)\n",
    "\n",
    "        # Train the SVM model using the best hyperparameters\n",
    "        clf = SVC(C=best_C, gamma=best_gamma, kernel='rbf')\n",
    "        clf.fit(X_train, Y_train)\n",
    "\n",
    "        # Calculate train accuracy\n",
    "        train_accuracy = clf.score(X_train, Y_train)\n",
    "        trial_train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Calculate validation accuracy\n",
    "        validation_accuracy = clf.score(X_val, Y_val)\n",
    "        trial_validation_accuracies.append(validation_accuracy)\n",
    "\n",
    "        # Calculate test accuracy\n",
    "        test_accuracy = clf.score(X_test, Y_test)\n",
    "        trial_test_accuracies.append(test_accuracy)\n",
    "\n",
    "        # Calculate precision, recall, and F1-score\n",
    "        Y_test_pred = clf.predict(X_test)\n",
    "        trial_precisions.append(precision_score(Y_test, Y_test_pred, average=\"weighted\", zero_division=0))\n",
    "        trial_recalls.append(recall_score(Y_test, Y_test_pred, average=\"weighted\"))\n",
    "        trial_f1_scores.append(f1_score(Y_test, Y_test_pred, average=\"weighted\"))\n",
    "\n",
    "    # Calculate and store split-wise average metrics\n",
    "    avg_train_accuracy = np.mean(trial_train_accuracies)\n",
    "    avg_validation_accuracy = np.mean(trial_validation_accuracies)\n",
    "    avg_test_accuracy = np.mean(trial_test_accuracies)\n",
    "    avg_precision = np.mean(trial_precisions)\n",
    "    avg_recall = np.mean(trial_recalls)\n",
    "    avg_f1_score = np.mean(trial_f1_scores)\n",
    "\n",
    "    split_results_svm_2.append({\n",
    "        'Split': f\"{int(train_size * 100)}/{int(test_size * 100)}\",\n",
    "        'ACC': avg_test_accuracy,\n",
    "        'Precision': avg_precision,\n",
    "        'Recall': avg_recall,\n",
    "        'F1-Score': avg_f1_score\n",
    "    })\n",
    "\n",
    "    # Print split-specific results\n",
    "    print(f\"\\nResults for {int(train_size * 100)}/{int(test_size * 100)} Split:\")\n",
    "    print(f\"Train Accuracy: {avg_train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {avg_test_accuracy:.4f}\")\n",
    "    # print(f\"Precision: {avg_precision:.4f}\")\n",
    "    # print(f\"Recall: {avg_recall:.4f}\")\n",
    "    # print(f\"F1-Score: {avg_f1_score:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df2f0e8-7e5b-44df-aef9-cf9c8b2370e0",
   "metadata": {},
   "source": [
    "#### Results for SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d389de60-0354-4d16-adf6-62490afc86e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Results on Fertility Dataset:\n",
      "Split     ACC            Precision      Recall         F1-Score       \n",
      "---------------------------------------------------------------------------\n",
      "80/20     1.0000         1.0000         1.0000         1.0000         \n",
      "50/50     0.8800         0.7744         0.8800         0.8238         \n",
      "20/80     0.8906         0.7932         0.8906         0.8391         \n",
      "---------------------------------------------------------------------------\n",
      "Overall   0.9235         0.8559         0.9235         0.8876         \n"
     ]
    }
   ],
   "source": [
    "# Calculate overall metrics for the SVM classifier\n",
    "overall_accuracy_2 = np.mean([r['ACC'] for r in split_results_svm_2])\n",
    "overall_precision_2 = np.mean([r['Precision'] for r in split_results_svm_2])\n",
    "overall_recall_2 = np.mean([r['Recall'] for r in split_results_svm_2])\n",
    "overall_f1_score_2 = np.mean([r['F1-Score'] for r in split_results_svm_2])\n",
    "\n",
    "# Create a formatted table for the split results\n",
    "print(\"SVM Classifier Results on Fertility Dataset:\")\n",
    "print(f\"{'Split':<10}{'ACC':<15}{'Precision':<15}{'Recall':<15}{'F1-Score':<15}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "# Loop through the split results and display each row\n",
    "for result in split_results_svm_2:\n",
    "    print(f\"{result['Split']:<10}{result['ACC']:<15.4f}{result['Precision']:<15.4f}{result['Recall']:<15.4f}{result['F1-Score']:<15.4f}\")\n",
    "\n",
    "# Print the overall metrics as the last row\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'Overall':<10}{overall_accuracy_2:<15.4f}{overall_precision_2:<15.4f}{overall_recall_2:<15.4f}{overall_f1_score_2:<15.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb44769-664d-4c0c-a9c8-55c780d59a21",
   "metadata": {},
   "source": [
    "### Classifier #3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c47503d-492b-4f9a-a6d2-211168db9890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracies for Each Hyperparameter Combination:\n",
      "==================================================\n",
      "Parameters: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}, Validation Accuracy: 0.8944\n",
      "Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}, Validation Accuracy: 0.8944\n",
      "Parameters: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}, Validation Accuracy: 0.8944\n",
      "Parameters: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}, Validation Accuracy: 0.8444\n",
      "Parameters: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}, Validation Accuracy: 0.8444\n",
      "\n",
      "Best Hyperparameters:\n",
      "  {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Validation Accuracy with Best Hyperparameters: 0.8944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Assuming `X_train`, `y_train` are already defined.\n",
    "\n",
    "# Hyperparameter tuning for Logistic Regression\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l2'], 'solver': ['lbfgs']}\n",
    "stratified_kfold = StratifiedKFold(n_splits=2)\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=10000), param_grid, cv=stratified_kfold, scoring='accuracy', return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract the results from the grid search\n",
    "cv_results = grid_search.cv_results_\n",
    "\n",
    "# Print the validation accuracies for each hyperparameter combination\n",
    "print(\"Validation Accuracies for Each Hyperparameter Combination:\")\n",
    "print(\"=\" * 50)\n",
    "for mean_val_acc, params in zip(cv_results['mean_test_score'], cv_results['params']):\n",
    "    print(f\"Parameters: {params}, Validation Accuracy: {mean_val_acc:.4f}\")\n",
    "\n",
    "# Best hyperparameters based on validation accuracy\n",
    "best_params = grid_search.best_params_\n",
    "best_validation_accuracy = grid_search.best_score_\n",
    "\n",
    "# Print the best hyperparameters and the corresponding validation accuracy\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"  {best_params}\")\n",
    "print(f\"Validation Accuracy with Best Hyperparameters: {best_validation_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98b1376b-f24a-4725-80fa-06d5ca963bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for 80/20 Split:\n",
      "Avg Train Accuracy = 0.8945\n",
      "Avg Test Accuracy = 0.9167\n",
      "Avg Validation Accuracy = 0.8542\n",
      "--------------------------------------------------\n",
      "\n",
      "Results for 50/50 Split:\n",
      "Avg Train Accuracy = 0.8776\n",
      "Avg Test Accuracy = 0.8667\n",
      "Avg Validation Accuracy = 0.9333\n",
      "--------------------------------------------------\n",
      "\n",
      "Results for 20/80 Split:\n",
      "Avg Train Accuracy = 0.8947\n",
      "Avg Test Accuracy = 0.8854\n",
      "Avg Validation Accuracy = 0.8958\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "best_C = 0.01\n",
    "best_penalty = 'l2'\n",
    "best_solver = 'lbfgs'\n",
    "\n",
    "# Assuming `X` and `y` are your feature and target arrays\n",
    "# Split ratios\n",
    "split_ratios = [(0.8, 0.2), (0.5, 0.5), (0.2, 0.8)]\n",
    "\n",
    "# Lists for storing accuracies and other metrics\n",
    "split_results_logreg = []\n",
    "\n",
    "# Iterate over splits\n",
    "for train_size, test_size in split_ratios:\n",
    "    trial_train_accuracies = []\n",
    "    trial_validation_accuracies = []\n",
    "    trial_test_accuracies = []\n",
    "    trial_precisions = []\n",
    "    trial_recalls = []\n",
    "    trial_f1_scores = []\n",
    "    \n",
    "    for _ in range(3):  # Running 3 trials\n",
    "        # Split the data into train and temp (validation + test)\n",
    "        X_train, X_temp, Y_train, Y_temp = train_test_split(X, y, train_size=train_size, random_state=None)\n",
    "        \n",
    "        # Now split the temp data into validation and test\n",
    "        X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=test_size, random_state=None)\n",
    "\n",
    "        # Train the Logistic Regression model using the best hyperparameters\n",
    "        clf = LogisticRegression(C=best_C, penalty=best_penalty, solver=best_solver, max_iter=10000)\n",
    "        clf.fit(X_train, Y_train)\n",
    "\n",
    "        # Calculate the accuracy on the training set\n",
    "        train_accuracy = clf.score(X_train, Y_train)\n",
    "        trial_train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Calculate the accuracy on the validation set\n",
    "        validation_accuracy = clf.score(X_val, Y_val)\n",
    "        trial_validation_accuracies.append(validation_accuracy)\n",
    "\n",
    "        # Calculate the accuracy on the test set\n",
    "        test_accuracy = clf.score(X_test, Y_test)\n",
    "        trial_test_accuracies.append(test_accuracy)\n",
    "\n",
    "        # Calculate precision, recall, and F1-score on the test set\n",
    "        Y_test_pred = clf.predict(X_test)\n",
    "        precision = precision_score(Y_test, Y_test_pred, average=\"weighted\", zero_division=0)\n",
    "        recall = recall_score(Y_test, Y_test_pred, average=\"weighted\")\n",
    "        f1 = f1_score(Y_test, Y_test_pred, average=\"weighted\")\n",
    "        trial_precisions.append(precision)\n",
    "        trial_recalls.append(recall)\n",
    "        trial_f1_scores.append(f1)\n",
    "\n",
    "    # Calculate and store average metrics for the current split\n",
    "    avg_train_accuracy = np.mean(trial_train_accuracies)\n",
    "    avg_validation_accuracy = np.mean(trial_validation_accuracies)\n",
    "    avg_test_accuracy = np.mean(trial_test_accuracies)\n",
    "    avg_precision = np.mean(trial_precisions)\n",
    "    avg_recall = np.mean(trial_recalls)\n",
    "    avg_f1_score = np.mean(trial_f1_scores)\n",
    "\n",
    "    split_results_logreg.append({\n",
    "        'Split': f\"{int(train_size * 100)}/{int(test_size * 100)}\",\n",
    "        'Test Accuracy': avg_test_accuracy,\n",
    "        'Precision': avg_precision,\n",
    "        'Recall': avg_recall,\n",
    "        'F1-Score': avg_f1_score\n",
    "    })\n",
    "\n",
    "    # Print split-specific results\n",
    "    print(f\"\\nResults for {int(train_size * 100)}/{int(test_size * 100)} Split:\")\n",
    "    print(f\"Avg Train Accuracy = {avg_train_accuracy:.4f}\")\n",
    "    print(f\"Avg Test Accuracy = {avg_test_accuracy:.4f}\")\n",
    "    print(f\"Avg Validation Accuracy = {avg_validation_accuracy:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa419b9-63c8-4c5b-b059-c1bf26baf2f2",
   "metadata": {},
   "source": [
    "#### Results for Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2ae2670-abfb-4bfe-902f-f282c932e115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Classifier Results on Fertility Dataset:\n",
      "Split     ACC            Precision      Recall         F1-Score       \n",
      "----------------------------------------------------------------------\n",
      "80/20     0.9167         0.8542         0.9167         0.8810         \n",
      "50/50     0.8667         0.7536         0.8667         0.8055         \n",
      "20/80     0.8854         0.7847         0.8854         0.8318         \n",
      "----------------------------------------------------------------------\n",
      "Overall   0.8896         0.7975         0.8896         0.8394         \n"
     ]
    }
   ],
   "source": [
    "# Calculate overall metrics\n",
    "overall_accuracy_3 = np.mean([r['Test Accuracy'] for r in split_results_logreg])\n",
    "overall_precision_3 = np.mean([r['Precision'] for r in split_results_logreg])\n",
    "overall_recall_3 = np.mean([r['Recall'] for r in split_results_logreg])\n",
    "overall_f1_score_3 = np.mean([r['F1-Score'] for r in split_results_logreg])\n",
    "\n",
    "# Create a formatted table for the split results\n",
    "print(\"\\nLogistic Regression Classifier Results on Fertility Dataset:\")\n",
    "print(f\"{'Split':<10}{'ACC':<15}{'Precision':<15}{'Recall':<15}{'F1-Score':<15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Loop through the split results and display each row\n",
    "for result in split_results_logreg:\n",
    "    print(f\"{result['Split']:<10}{result['Test Accuracy']:<15.4f}{result['Precision']:<15.4f}{result['Recall']:<15.4f}{result['F1-Score']:<15.4f}\")\n",
    "\n",
    "# Print the overall metrics as the last row\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Overall':<10}{overall_accuracy_3:<15.4f}{overall_precision_3:<15.4f}{overall_recall_3:<15.4f}{overall_f1_score_3:<15.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8622ac-ebeb-4825-a77a-68855d222a0e",
   "metadata": {},
   "source": [
    "## Final Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e8e7e6b-8d81-4dbf-a746-55d54b6d34a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Summary Table of Overall Metrics:\n",
      "                Classifier       ACC  Precision    Recall  F1-Score\n",
      "0            Decision Tree  0.797222   0.832157  0.797222  0.809264\n",
      "1  Support Vector Machines  0.923542   0.855871  0.923542  0.887644\n",
      "2      Logistic Regression  0.889583   0.797478  0.889583  0.839435\n"
     ]
    }
   ],
   "source": [
    "summary_data = {\n",
    "    'Classifier': ['Decision Tree', 'Support Vector Machines', 'Logistic Regression'],  # Add names for all classifiers\n",
    "    'ACC': [overall_accuracy_1, overall_accuracy_2, overall_accuracy_3],  # Add more as needed\n",
    "    'Precision': [overall_precision_1, overall_precision_2, overall_precision_3],\n",
    "    'Recall': [overall_recall_1, overall_recall_2, overall_recall_3],\n",
    "    'F1-Score': [overall_f1_score_1, overall_f1_score_2, overall_f1_score_3]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame for cleaner display\n",
    "import pandas as pd\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Print the summary table\n",
    "print(\"Final Summary Table of Overall Metrics:\")\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d65ee6-72c8-4da0-bf34-de71d29d18f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
